ymin <-  if (is.null(cl4.object$xyCoords$lat))  min(cl4.object$xyCoords$y) else  min(cl4.object$xyCoords$lat[,1])
ymax <-  if (is.null(cl4.object$xyCoords$lat))  max(cl4.object$xyCoords$y) else  max(cl4.object$xyCoords$lat[,1])
rasters <- raster::raster(
as.factor(as.character(cl4.object$Data)),
xmn = xmin,
xmx = xmax,
ymn = ymin,
ymx = ymax
) %>%
flip(., direction = 'y')
return(rasters)
}
lnd.1 <- loadGridData("Databases/land_cover/ESACCI-LC-L4-LCCS-Map-300m-P1Y-1992-v2.0.7cds.nc",
var = "lccs_class", lonLim = c(10,12), latLim = c(30,40))
try <- make_raster(lnd.1)
make_raster <- function(cl4.object) {
if (length(dim(cl4.object$Data)) != 2)
stop("Your data needs to be a 2d array, check dimension")
xmin <- if (is.null(cl4.object$xyCoords$lon))  min(cl4.object$xyCoords$x) else  min(cl4.object$xyCoords$lon[1,])
xmax <-  if (is.null(cl4.object$xyCoords$lon))  max(cl4.object$xyCoords$x) else  max(cl4.object$xyCoords$lon[1,])
ymin <-  if (is.null(cl4.object$xyCoords$lat))  min(cl4.object$xyCoords$y) else  min(cl4.object$xyCoords$lat[,1])
ymax <-  if (is.null(cl4.object$xyCoords$lat))  max(cl4.object$xyCoords$y) else  max(cl4.object$xyCoords$lat[,1])
rasters <- raster::raster(
cl4.object$Data,
xmn = xmin,
xmx = xmax,
ymn = ymin,
ymx = ymax
) %>%
flip(., direction = 'y')
return(rasters)
}
try <- make_raster(lnd.1)
make_raster <- function(cl4.object) {
if (length(dim(cl4.object$Data)) != 2)
stop("Your data needs to be a 2d array, check dimension")
xmin <- if (is.null(cl4.object$xyCoords$lon))  min(cl4.object$xyCoords$x) else  min(cl4.object$xyCoords$lon[1,])
xmax <-  if (is.null(cl4.object$xyCoords$lon))  max(cl4.object$xyCoords$x) else  max(cl4.object$xyCoords$lon[1,])
ymin <-  if (is.null(cl4.object$xyCoords$lat))  min(cl4.object$xyCoords$y) else  min(cl4.object$xyCoords$lat[,1])
ymax <-  if (is.null(cl4.object$xyCoords$lat))  max(cl4.object$xyCoords$y) else  max(cl4.object$xyCoords$lat[,1])
rasters <- raster::raster(
as.factor(as.character(cl4.object$Data)),
xmn = xmin,
xmx = xmax,
ymn = ymin,
ymx = ymax
) %>%
flip(., direction = 'y')
return(rasters)
}
try <- make_raster(lnd.1)
rownames(lnd.1$Data) <- lnd.1$xyCoords$y
colnames(lnd.1$Data) <-  lnd.1$xyCoords$x
out <- as.data.frame(as.table(lnd.1$Data)) %>%
mutate(Freq=as.factor(as.character(Freq)))
unique(out$Freq)
dataInventory("Databases/land_cover/ESACCI-LC-L4-LCCS-Map-300m-P1Y-1992-v2.0.7cds.nc")
lnd.2 <- loadGridData("Databases/land_cover/C3S-LC-L4-LCCS-Map-300m-P1Y-2020-v2.1.1.nc",
var = "lccs_class", lonLim = c(10,12), latLim = c(30,40))
unique(as.vector(lnd.2$Data))
Camb <- getData("GADM", country="Cambodia", level=1)
Camb@bbox[1,1]
Camb@bbox[[1,1]]
Camb@bbox
lnd.1 <- loadGridData("Databases/land_cover/ESACCI-LC-L4-LCCS-Map-300m-P1Y-1992-v2.0.7cds.nc",
var = "lccs_class", lonLim = c( Camb@bbox[[1,1]], Camb@bbox[[1,2]]), latLim = c( Camb@bbox[[2,1]], Camb@bbox[[2,2]]))
rownames(lnd.1$Data) <- lnd.1$xyCoords$y
colnames(lnd.1$Data) <-  lnd.1$xyCoords$x
out <- as.data.frame(as.table(lnd.1$Data)) %>%
mutate(Freq=as.factor(as.character(Freq)))
ggplot(out)+
geom_raster(aes(x = Var1, y = Var2, fill = factor(Freq)),
alpha = 0.7)+
theme(
plot.background = element_blank(),
panel.background = element_rect(fill = 'aliceblue'),
panel.border = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.text= element_blank(),
axis.ticks = element_blank(),
axis.title=element_blank(),
legend.position = "bottom",
legend.direction = "horizontal",
legend.key.height= unit(0.5, 'cm'),
legend.key.width= unit(2, 'cm'),
legend.box.spacing = unit(0, "pt")
)
unique(lnd.1$Data)
unique(as.vector(lnd.1$Data))
out <- as.data.frame(as.table(lnd.1$Data)) %>%
mutate(Freq=as.factor(as.character(Freq)), class=ifelse(is.numeric(Freq), Freq, "NA"))
View(out)
ggplot(out)+
geom_raster(aes(x = Var1, y = Var2, fill = factor(class)),
alpha = 0.7)+
theme(
plot.background = element_blank(),
panel.background = element_rect(fill = 'aliceblue'),
panel.border = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.text= element_blank(),
axis.ticks = element_blank(),
axis.title=element_blank(),
legend.position = "bottom",
legend.direction = "horizontal",
legend.key.height= unit(0.5, 'cm'),
legend.key.width= unit(2, 'cm'),
legend.box.spacing = unit(0, "pt")
)
out <- as.data.frame(as.table(lnd.1$Data)) %>%
mutate(class=ifelse(is.numeric(Freq), Freq, "NA"))
ggplot(out)+
geom_raster(aes(x = Var1, y = Var2, fill = factor(class)),
alpha = 0.7)+
theme(
plot.background = element_blank(),
panel.background = element_rect(fill = 'aliceblue'),
panel.border = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.text= element_blank(),
axis.ticks = element_blank(),
axis.title=element_blank(),
legend.position = "bottom",
legend.direction = "horizontal",
legend.key.height= unit(0.5, 'cm'),
legend.key.width= unit(2, 'cm'),
legend.box.spacing = unit(0, "pt")
)
unique(out$class)
ggplot(out)+
geom_raster(aes(x = Var1, y = Var2, fill = factor(Freq)),
alpha = 0.7)+
theme(
plot.background = element_blank(),
panel.background = element_rect(fill = 'aliceblue'),
panel.border = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.text= element_blank(),
axis.ticks = element_blank(),
axis.title=element_blank(),
legend.position = "bottom",
legend.direction = "horizontal",
legend.key.height= unit(0.5, 'cm'),
legend.key.width= unit(2, 'cm'),
legend.box.spacing = unit(0, "pt")
)
out <- as.data.frame(as.table(lnd.1$Data)) %>%
mutate(Freq=as.factor(as.character(Freq)), class=ifelse(is.numeric(Freq), Freq, "NA"))
ggplot(out)+
geom_raster(aes(x = Var1, y = Var2, fill = factor(Freq)),
alpha = 0.7)+
theme(
plot.background = element_blank(),
panel.background = element_rect(fill = 'aliceblue'),
panel.border = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.text= element_blank(),
axis.ticks = element_blank(),
axis.title=element_blank(),
legend.position = "bottom",
legend.direction = "horizontal",
legend.key.height= unit(0.5, 'cm'),
legend.key.width= unit(2, 'cm'),
legend.box.spacing = unit(0, "pt")
)
lnd.1$Data
lnd.1$Data[[1:10,1:10]]
lnd.1$Data[1:10,1:10]
unique(as.vector(lnd.1$Data))
lnd.1 <- loadGridData("Databases/land_cover/ESACCI-LC-L4-LCCS-Map-300m-P1Y-1992-v2.0.7cds.nc",
var = "lccs_class", lonLim = c( Camb@bbox[[1,1]], Camb@bbox[[1,2]]), latLim = c( Camb@bbox[[2,1]], Camb@bbox[[2,2]]))
unique(as.vector(lnd.1$Data))
lnd.1$Data[1:10,1:10]
lnd.1$Data[50:60,50:60]
unique(as.vector(lnd.1$Data))
rownames(lnd.1$Data) <- lnd.1$xyCoords$y
colnames(lnd.1$Data) <-  lnd.1$xyCoords$x
out <- as.data.frame(as.table(lnd.1$Data)) %>%
mutate(Freq=as.factor(as.character(Freq)), class=ifelse(is.numeric(Freq), Freq, "NA"))
ggplot(out)+
geom_raster(aes(x = Var1, y = Var2, fill = factor(Freq)),
alpha = 0.7)+
theme(
plot.background = element_blank(),
panel.background = element_rect(fill = 'aliceblue'),
panel.border = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.text= element_blank(),
axis.ticks = element_blank(),
axis.title=element_blank()
)
unique(as.vector(lnd.1$Data))
length(unique(as.vector(lnd.1$Data)))
dataInventory("Databases/land_cover/ESACCI-LC-L4-LCCS-Map-300m-P1Y-1992-v2.0.7cds.nc")
length(unique(as.vector(lnd.1$Data)))
unique(as.vector(lnd.1$Data))
lnd.1 <- loadGridData("Databases/land_cover/ESACCI-LC-L4-LCCS-Map-300m-P1Y-1992-v2.0.7cds.nc",
var = "change_count", lonLim = c( Camb@bbox[[1,1]], Camb@bbox[[1,2]]), latLim = c( Camb@bbox[[2,1]], Camb@bbox[[2,2]]))
unique(as.vector(lnd.1$Data))
rownames(lnd.1$Data) <- lnd.1$xyCoords$y
colnames(lnd.1$Data) <-  lnd.1$xyCoords$x
out <- as.data.frame(as.table(lnd.1$Data)) %>%
mutate(Freq=as.factor(as.character(Freq)), class=ifelse(is.numeric(Freq), Freq, "NA"))
out <- as.data.frame(as.table(lnd.1$Data)) %>%
mutate(Freq=as.factor(as.character(Freq)))
ggplot(out)+
geom_raster(aes(x = Var1, y = Var2, fill = factor(Freq)),
alpha = 0.7)+
theme(
plot.background = element_blank(),
panel.background = element_rect(fill = 'aliceblue'),
panel.border = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.text= element_blank(),
axis.ticks = element_blank(),
axis.title=element_blank()
)
unique(as.vector(lnd.1$Data))
lnd.1 <- loadGridData("Databases/land_cover/ESACCI-LC-L4-LCCS-Map-300m-P1Y-1992-v2.0.7cds.nc",
var = "lcc_level", lonLim = c( Camb@bbox[[1,1]], Camb@bbox[[1,2]]), latLim = c( Camb@bbox[[2,1]], Camb@bbox[[2,2]]))
dataInventory("Databases/land_cover/ESACCI-LC-L4-LCCS-Map-300m-P1Y-1992-v2.0.7cds.nc")
dataInventory("Databases/land_cover/ESACCI-LC-L4-LCCS-Map-300m-P1Y-1992-v2.0.7cds.nc")$try
lnd.1 <- loadGridData("Databases/land_cover/ESACCI-LC-L4-LCCS-Map-300m-P1Y-1992-v2.0.7cds.nc",
var = "lccs_class", lonLim = c( Camb@bbox[[1,1]], Camb@bbox[[1,2]]), latLim = c( Camb@bbox[[2,1]], Camb@bbox[[2,2]]))
unique(as.vector(lnd.1$Data))
lnd.1 <- loadGridData("Downloads/dataset-satellite-land-cover-3b78f8aa-b42d-4a00-a1ba-59234410b147/C3S-LC-L4-LCCS-Map-300m-P1Y-2020-v2.1.1.nc",
var = "lccs_class", lonLim = c( Camb@bbox[[1,1]], Camb@bbox[[1,2]]), latLim = c( Camb@bbox[[2,1]], Camb@bbox[[2,2]]))
unique(as.vector(lnd.1$Data))
ps.sv <- readRDS("../../data/Phyloseq_data/ps_sv_PVC.rds")
# setting working directory
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
library(mvabund)
library(lattice)
library(corrplot)
library(phyloseq)
library(tidyverse)
library(metagMisc)
library(metacoder)
library(spaa)
ps.sv <- readRDS("../../data/Phyloseq_data/ps_sv_PVC.rds")
ps.sv <- readRDS("../data/Phyloseq_data/ps_sv_PVC.rds")
ps.sv <- readRDS("../data/Phyloseq_data/ps_sv_PVC.rds")
# Removing SVs that based on 1% prevalence and 20 reads abundance. This was applied to all phyloseq objects prior to any statistical analysis.
ps.sv <- phyloseq_filter_prevalence(ps.sv, prev.trh = 0.01, abund.trh = 20, threshold_condition = "OR", abund.type = "total")
# reading in sample data and otu table
samp.data <- data.frame(sample_data(ps.sv))
otu.table <- t(as.data.frame(otu_table(ps.sv)))
# making otu table as mv abund object
otu.MV <- mvabund(otu.table)
rm(list=ls())
ps.sv <- readRDS("../data/Phyloseq_data/ps_sv_PVC.rds")
# Removing SVs that based on 1% prevalence and 20 reads abundance. This was applied to all phyloseq objects prior to any statistical analysis.
ps.sv <- phyloseq_filter_prevalence(ps.sv, prev.trh = 0.01, abund.trh = 20, threshold_condition = "OR", abund.type = "total")
# reading in sample data and otu table
samp.data <- data.frame(sample_data(ps.sv))
sv.table <- t(as.data.frame(otu_table(ps.sv)))
# making otu table as mv abund object
sv.MV <- mvabund(sv.table)
#fitting the null model
ft_null=manyglm(sv.MV ~1, data=samp.data)
# offset as difference between total counts per sample and the NULL model. This account for different sequencing depths.
# for more info see (https://onlinelibrary.wiley.com/doi/10.1111/1755-0998.13703?af=R)
QDoffset = log(rowSums(sv.MV)) - log(rowSums(predict.manyglm(ft_null)))
samp.data2 <- samp.data %>%
dplyr::select(Subpopulation, Status, Dom_event,   12:24, -Weight,)
colnames(samp.data2)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# loading the phyloseq object filtered to remove SVs not present
ps.sv <- readRDS("../../3.filtering/results/tables/ps_sv_filt.rds")
# Removing SVs that are present at 1% and have total count lower than 20
ps.sv <- phyloseq_filter_prevalence(ps.sv, prev.trh = 0.01, abund.trh = 20, threshold_condition = "OR", abund.type = "total")
# samples needs to be in rows
otu.table <- t(as.data.frame(otu_table(ps.sv)))
# reading in sample data
samp.data <- data.frame(sample_data(ps.sv))
# inclusind collection time
collection_time <- read_excel("../../../../../../../Accessions to choose/datasets/Stations_collection_year.xlsx") %>%
select(ACCESION, 'COLLECTED YEAR') %>%
rename(Sample_ID=ACCESION, C.year='COLLECTED YEAR') %>%
mutate(Sample_ID=str_squish(Sample_ID)) %>%
mutate(Sample_ID=str_remove(Sample_ID, " "), C.year=as.numeric(C.year)) %>%
mutate(C.year.d=C.year-2019) %>%
mutate(C.year.d=C.year.d*-1)
samp.data <- left_join(samp.data, collection_time)
# inclusind collection time
collection_time <- read_excel("../../../../../../../Accessions to choose/datasets/Stations_collection_year.xlsx") %>%
select(ACCESION, 'COLLECTED YEAR') %>%
rename(Sample_ID=ACCESION, C.year='COLLECTED YEAR') %>%
mutate(Sample_ID=str_squish(Sample_ID)) %>%
mutate(Sample_ID=str_remove(Sample_ID, " "), C.year=as.numeric(C.year)) %>%
mutate(C.year.d=C.year-2019) %>%
mutate(C.year.d=C.year.d*-1)
library(readxl)
# inclusind collection time
collection_time <- read_excel("../../../../../../../Accessions to choose/datasets/Stations_collection_year.xlsx") %>%
select(ACCESION, 'COLLECTED YEAR') %>%
rename(Sample_ID=ACCESION, C.year='COLLECTED YEAR') %>%
mutate(Sample_ID=str_squish(Sample_ID)) %>%
mutate(Sample_ID=str_remove(Sample_ID, " "), C.year=as.numeric(C.year)) %>%
mutate(C.year.d=C.year-2019) %>%
mutate(C.year.d=C.year.d*-1)
samp.data <- left_join(samp.data, collection_time)
colnames(samp.data)
sample_data(ps.sv)= samp.data
sample_data(ps.sv)
sample_data(ps.sv)= sample_data(samp.data)
sample_data(samp.data)
sample_data(ps.sv)
ps.sv@sam_data= sample_data(samp.data)
sample_data(ps.sv)
saveRDS(ps.sv, "~/Desktop/ps_sv_PVC.rds")
rm(list=ls())
library(mvabund)
library(lattice)
library(corrplot)
library(phyloseq)
library(tidyverse)
library(metagMisc)
library(parallel)
# setting working directory
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
ps.sv <- readRDS("../data/Phyloseq_data/ps_sv_PVC.rds")
# Removing SVs that based on 1% prevalence and 20 reads abundance. This was applied to all phyloseq objects prior to any statistical analysis.
ps.sv <- phyloseq_filter_prevalence(ps.sv, prev.trh = 0.01, abund.trh = 20, threshold_condition = "OR", abund.type = "total")
# reading in sample data and otu table
samp.data <- data.frame(sample_data(ps.sv))
sv.table <- t(as.data.frame(otu_table(ps.sv)))
# making otu table as mv abund object
sv.MV <- mvabund(sv.table)
#fitting the null model
ft_null=manyglm(sv.MV ~1, data=samp.data)
# offset as difference between total counts per sample and the NULL model. This account for different sequencing depths.
# for more info see (https://onlinelibrary.wiley.com/doi/10.1111/1755-0998.13703?af=R)
QDoffset = log(rowSums(sv.MV)) - log(rowSums(predict.manyglm(ft_null)))
samp.data2 <- samp.data %>%
dplyr::select(Subpopulation, Status, Dom_event,   12:24, -Weight,)
colnames(samp.data2 )
colnames(samp.data)
# setting working directory
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
ps.sv <- readRDS("../data/Phyloseq_data/ps_sv_PVC.rds")
# Removing SVs that based on 1% prevalence and 20 reads abundance. This was applied to all phyloseq objects prior to any statistical analysis.
ps.sv <- phyloseq_filter_prevalence(ps.sv, prev.trh = 0.01, abund.trh = 20, threshold_condition = "OR", abund.type = "total")
# reading in sample data and otu table
samp.data <- data.frame(sample_data(ps.sv))
sv.table <- t(as.data.frame(otu_table(ps.sv)))
# making otu table as mv abund object
sv.MV <- mvabund(sv.table)
#fitting the null model
ft_null=manyglm(sv.MV ~1, data=samp.data)
# offset as difference between total counts per sample and the NULL model. This account for different sequencing depths.
# for more info see (https://onlinelibrary.wiley.com/doi/10.1111/1755-0998.13703?af=R)
QDoffset = log(rowSums(sv.MV)) - log(rowSums(predict.manyglm(ft_null)))
samp.data2 <- samp.data %>%
dplyr::select(Subpopulation, Status, Dom_event,   12:24, -Weight,)
View(samp.data2)
samp.data2 <- samp.data %>%
dplyr::select(Subpopulation, Status, Dom_event,   12:24, -Weight,) %>%
mutate(Dom_event=case_when(Subpopulation=="WA1" ~ "AW",
Subpopulation=="M3" ~ "MW",
Subpopulation=="M4" ~ "MW",
Subpopulation=="WA2" ~ "AW",
Subpopulation=="DA1" ~ "AD",
Subpopulation=="M2" ~ "MD"))
aic = rep(NA,ncol(samp.data2))
names(aic) = colnames(samp.data2)
rm(list=ls())
# setting working directory
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
ps.sv <- readRDS("../data/Phyloseq_data/ps_sv_PVC.rds")
# Removing SVs that based on 1% prevalence and 20 reads abundance. This was applied to all phyloseq objects prior to any statistical analysis.
ps.sv <- phyloseq_filter_prevalence(ps.sv, prev.trh = 0.01, abund.trh = 20, threshold_condition = "OR", abund.type = "total")
# reading in sample data and otu table
samp.data <- data.frame(sample_data(ps.sv))
sv.table <- t(as.data.frame(otu_table(ps.sv)))
# making otu table as mv abund object
sv.MV <- mvabund(sv.table)
#fitting the null model
ft_null=manyglm(sv.MV ~1, data=samp.data)
# offset as difference between total counts per sample and the NULL model. This account for different sequencing depths.
# for more info see (https://onlinelibrary.wiley.com/doi/10.1111/1755-0998.13703?af=R)
QDoffset = log(rowSums(sv.MV)) - log(rowSums(predict.manyglm(ft_null)))
samp.data2 <- samp.data %>%
dplyr::select(Subpopulation, Status, Dom_event,   12:24, -Weight,) %>%
mutate(Dom_event=case_when(Subpopulation=="WA1" ~ "AW",
Subpopulation=="M3" ~ "MW",
Subpopulation=="M4" ~ "MW",
Subpopulation=="WA2" ~ "AW",
Subpopulation=="DA1" ~ "AD",
Subpopulation=="M2" ~ "MD"))
aic = rep(NA,ncol(samp.data2))
names(aic) = colnames(samp.data2)
# calculating AIC for each variable. COnsidering a quadratic term only when it leads to a lower AIC
for (iVar in 1:ncol(samp.data2)) {
if(is.numeric(samp.data2[,iVar])) {
glms = manyglm(sv.MV~ samp.data2[,iVar], data = samp.data2, offset = QDoffset)
glms_poly = manyglm(sv.MV~ poly(samp.data2[,iVar],2), data = samp.data2, offset = QDoffset)
if(glms_poly$AICsum <  glms$AICsum) { # inducing quadratic term only when better
aic[iVar] = glms_poly$AICsum
} else {
aic[iVar] = glms$AICsum
}
} else {
glms = manyglm(sv.MV~ samp.data2[,iVar], data = samp.data2, offset = QDoffset)
aic[iVar] = glms$AICsum
}
}
aic <- data.frame(aic=aic, var=names(aic))
aic %>%
mutate(var = fct_reorder(var, desc(aic))) %>%
ggplot(., aes(aic, var))+
geom_bar(stat = "identity", fill="red", color="black", alpha=0.5)+
theme_Publication(base_size = 11)+
ylab("AIC")+
theme(axis.text.x = element_text(angle=45, vjust=0.5))+
coord_cartesian(xlim = c(72500, 78900))
aic %>%
mutate(var = fct_reorder(var, desc(aic))) %>%
ggplot(., aes(aic, var))+
geom_bar(stat = "identity", fill="red", color="black", alpha=0.5)+
theme_bw(base_size = 11)+
ylab("AIC")+
theme(axis.text.x = element_text(angle=45, vjust=0.5))+
coord_cartesian(xlim = c(72500, 78900))
samp.data3 <- samp.data %>%
mutate_at(c("Ca","C.year"), ~(scale(.) %>% as.vector))
glm_best2 = manyglm(otu.MV~Ca+C.year+Regeneration_site,offset = QDoffset,data = samp.data3)
glm_best2 = manyglm(sv.MV~Ca+C.year+Regeneration_site,offset = QDoffset,data = samp.data3)
# the outout of this analysis can also be downloaded from GitHub
anova_glm_tot <- readRDS("../data/mvabund_data/anova_vulgaris_120.rds")
K=120 # cores
N=1  #bootstrapping
pi_Ca <- map_dbl(anova_PVC_120, ~ .x$table[2,4])
piMean_Ca = mean(pi_Ca)
pi_Ca <- map_dbl(anova_PVC_120, ~ .x$table[2,4])
pi_Ca <- map_dbl(anova_glm_tot, ~ .x$table[2,4])
piMean_Ca = mean(pi_Ca)
(p_Ca = piMean_Ca + (piMean_Ca-1)*(K-1)/(K*N+1)) # Ca is significant. p.value=0.008
pi_time <- map_dbl(anova_glm_tot , ~ .x$table[3,4])
piMean_time = mean(pi_time)
(p_time = piMean_time + (piMean_time-1)*(K-1)/(K*N+1)) # Sampling time is not significant. P.value = 0.13
# p-value for Regeneratino site
pi_site <- map_dbl(anova_glm_tot , ~ .x$table[4,4])
piMean_site = mean(pi_site)
(p_site = piMean_site + (piMean_site-1)*(K-1)/(K*N+1)) # Regeneration site is not significant. P.value = 0.13
# Therefore, the minimum adeguate model contains Ca only.
glm_best = manyglm(sv.MV~Ca,offset = QDoffset,data = samp.data)
coef <- data.frame(Ca=glm_best$coefficients[2,], SV=names(glm_best$coefficients[2,]))
ps.sv <- readRDS("../data/Phyloseq_data/ps_sv_PVC.rds")
ps.filt <- phyloseq_filter_prevalence(ps.sv, prev.trh = 0.05, abund.trh = NULL, threshold_condition = "OR", abund.type = "total")
# taxas filtered at 5% prevalence
tax.table <- data.frame(tax_table(ps.filt))
tax.table$SV <- rownames(tax.table)
# combining coefficients for taxa present at 5% prevalence
taxmtab.coef <- left_join(tax.table, coef)
taxmtab.coef %>%
filter(Phylum%in%c("Proteobacteria", "Acidobacteriota", "Actinobacteriota", "Bacteroidota", "Deinococcota", "Firmicutes")) %>%
mutate(Ca=ifelse(Ca<0,"Negative", "Positive")) %>%
group_by(Phylum, Ca) %>%
summarise(amount=n()) %>%
ungroup() %>%
group_by(Phylum) %>%
mutate(tot=sum(amount), r.a=(amount/tot)*100) %>%
ggplot()+
geom_bar(aes(Phylum,r.a,fill=Ca),stat="identity", color="black")+
ylab("Relative importance of coefficients")+
theme(axis.text.x = element_text(
size = 12, angle = 45, hjust = 1), axis.text.y=element_blank(),
axis.ticks.y=element_blank())
mglm_null <- manyglm(sv.MV~ 1, data = samp.data)
mglm_ca <- manyglm(sv.MV~ Ca, data = samp.data, offset = QDoffset)
mglm_ca$AICsum
mglm_ca$aic
mglm_status <- manyglm(sv.MV~ Status, data = samp.data, offset = QDoffset)
mglm_status$AICsum
mglm_ca$AICsum
# 53% of models have better AIC compared to Status as covariate
data.frame(ca=mglm_ca$aic, status=mglm_status$aic) %>%
mutate(diff=ca-status, res=ifelse(diff<0, "better", "worse"), rows=nrow(.)) %>%
filter(res=="better") %>%
mutate(rows.filt=nrow(.), perc=rows.filt/rows*100)
# Applying Ecocopula to confirm AIC results
copula.null <- cord(mglm_null)
library(ecoCopula)
# Applying Ecocopula to confirm AIC results
copula.null <- cord(mglm_null)
copula.Ca <- cord(mglm_ca)
# factor loading. Read page 396 of Eco-Stats: Data analysis in ecology. Note that these results can change slightly when repeated
ss_ca <- c(sum(copula.null$loadings^2), sum(copula.Ca$loadings^2))
c(ss_ca, 1-ss_ca[2]/ss_ca[1])
## Status
copula.Status <- cord(mglm_status)
# factor loadings. Read page 396 of Eco-Stats: Data analysis in ecology. Note that these results can change slightly when repeated
ss_st <- c(sum(copula.null$loadings^2), sum(copula.Status$loadings^2))
c(ss_st, 1-ss_st[2]/ss_st[1])
rm(list=ls())
library(mlr3)
library(phyloseq)
library(mlbench)
library(tidyverse)
library(metagMisc)
library(Boruta)
library(mlr)
library(parallel)
library(rlist)
